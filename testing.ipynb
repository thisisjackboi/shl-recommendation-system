{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6efcdb",
   "metadata": {},
   "source": [
    "# Indexing and preparing a collection of SHL assessments (from a JSON/CSV file) using the BM25 algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e424bf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 230 assessments with BM25.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# 1. Load assessments JSON\n",
    "with open(\"shl_assessments.json\", encoding=\"utf-8\") as f:\n",
    "    assessments = json.load(f)\n",
    "\n",
    "# 2. Prepare “documents” for BM25: name + description + test_type\n",
    "docs = []\n",
    "for a in assessments:\n",
    "    parts = [a[\"name\"]]\n",
    "    if desc := a.get(\"description\"):\n",
    "        parts.append(desc)\n",
    "    if tt := a.get(\"test_type\"):\n",
    "        parts += (tt if isinstance(tt, list) else [tt])\n",
    "    docs.append(\" \".join(parts).lower())\n",
    "\n",
    "# 3. Tokenize and initialize BM25\n",
    "tokenized = [doc.split() for doc in docs]\n",
    "bm25 = BM25Okapi(tokenized)\n",
    "\n",
    "print(f\"Indexed {len(assessments)} assessments with BM25.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c42f5",
   "metadata": {},
   "source": [
    "# combining traditional keyword-based search (BM25) with semantic similarity using Sentence Transformers for more accurate, context-aware ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got query embedding of size (384,) and 20 candidate embeddings.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# ——— Initialize once at startup ———\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def embed_texts(texts: list[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Embed a list of texts using a local SentenceTransformer.\n",
    "    Returns an (N × D) array of embeddings.\n",
    "    \"\"\"\n",
    "    # convert_to_numpy=True gives you an np.ndarray\n",
    "    return embed_model.encode(texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "\n",
    "# ——— = query = ———\n",
    "user_query = \"job desc\"\n",
    "\n",
    "#BM25 shortlist\n",
    "query_tokens = user_query.lower().split()\n",
    "bm25_scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "K = 20\n",
    "top_idx = np.argpartition(-bm25_scores, K)[:K]\n",
    "top_idx = top_idx[np.argsort(-bm25_scores[top_idx])]\n",
    "shortlist = [assessments[i] for i in top_idx]\n",
    "\n",
    "# 2) Embed the user query\n",
    "query_embedding = embed_texts([user_query])[0]  # shape: (D,)\n",
    "\n",
    "# 3) Prepare and embed each candidate\n",
    "cand_texts = [\n",
    "    \" \".join([c[\"name\"]] + (c.get(\"test_type\") or []))\n",
    "    for c in shortlist\n",
    "]\n",
    "candidate_embeddings = embed_texts(cand_texts)  # shape: (K, D)\n",
    "\n",
    "print(f\"Got query embedding of size {query_embedding.shape} and {candidate_embeddings.shape[0]} candidate embeddings.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe842799",
   "metadata": {},
   "source": [
    "#  hybrid semantic search system that returns the top N most relevant SHL assessments for a user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e20d4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Supervisor - Short Form (score: 0.293)\n",
      "   URL: https://www.shl.com/products/product-catalog/view/supervisor-short-form/\n",
      "   Duration: 1 min\n",
      "   Remote: False, Adaptive: False\n",
      "   Types: ['Simulations']\n",
      "\n",
      "2. Support Supervisor Solution (score: 0.210)\n",
      "   URL: https://www.shl.com/products/product-catalog/view/support-supervisor-solution/\n",
      "   Duration: 1 min\n",
      "   Remote: False, Adaptive: False\n",
      "   Types: ['Ability & Aptitude', 'Personality & Behavior', 'Simulations', 'Biodata & Situational Judgement']\n",
      "\n",
      "3. Supervisor 7.0 Solution (score: 0.176)\n",
      "   URL: https://www.shl.com/products/product-catalog/view/supervisor-7-0-solution/\n",
      "   Duration: 1 min\n",
      "   Remote: False, Adaptive: False\n",
      "   Types: ['Biodata & Situational Judgement', 'Competencies']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Compute cosine similarity between two 1-D arrays.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# ——— Given from Step 3 ———\n",
    "#   user_query\n",
    "#   shortlist: list of assessment-dicts (length K)\n",
    "#   query_embedding: np.ndarray, shape (D,)\n",
    "#   candidate_embeddings: np.ndarray, shape (K, D)\n",
    "\n",
    "N = 3  # final number of recommendations\n",
    "\n",
    "# 1) Compute similarity scores\n",
    "scores = [cosine_sim(query_embedding, emb) for emb in candidate_embeddings]\n",
    "\n",
    "# 2) Get top-N indices\n",
    "top_n_idx = np.argsort(scores)[-N:][::-1]  # descending order\n",
    "\n",
    "# 3) Build final recs\n",
    "final_recs = []\n",
    "for idx in top_n_idx:\n",
    "    a = shortlist[idx]\n",
    "    final_recs.append({\n",
    "        \"name\": a[\"name\"],\n",
    "        \"url\": a[\"url\"],\n",
    "        \"score\": scores[idx],\n",
    "        \"duration\": a.get(\"duration\"),\n",
    "        \"remote_testing\": a.get(\"remote_testing\", False),\n",
    "        \"adaptive_irt\": a.get(\"adaptive_irt\", False),\n",
    "        \"test_type\": a.get(\"test_type\", []),\n",
    "    })\n",
    "\n",
    "# 4) Output\n",
    "for i, rec in enumerate(final_recs, 1):\n",
    "    print(f\"{i}. {rec['name']} (score: {rec['score']:.3f})\")\n",
    "    print(f\"   URL: {rec['url']}\")\n",
    "    if rec[\"duration\"] is not None:\n",
    "        print(f\"   Duration: {rec['duration']} min\")\n",
    "    print(f\"   Remote: {rec['remote_testing']}, Adaptive: {rec['adaptive_irt']}\")\n",
    "    print(f\"   Types: {rec['test_type']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8556c6e7",
   "metadata": {},
   "source": [
    "# scraping and extracting the job description text from a given job posting URL, using requests and BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b2188f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job description not found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_url(url: str) -> str:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Look for the HTML element that contains the job description\n",
    "        # You may need to adjust these based on the platform\n",
    "        job_desc = soup.find('div', {'class': 'job-description'})  # Example for a common class\n",
    "        \n",
    "        if job_desc:\n",
    "            return job_desc.get_text(strip=True)\n",
    "        else:\n",
    "            return \"Job description not found.\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error fetching the URL: {e}\"\n",
    "\n",
    "# Test with a valid URL\n",
    "job_url = \"https://www.linkedin.com/jobs/view/research-engineer-ai-at-shl-4194768899/?originalSubdomain=in\"\n",
    "job_desc = extract_text_from_url(job_url)\n",
    "print(job_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75df009e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHL hiring Research Engineer, AI in Gurgaon, Haryana, India | LinkedIn Skip to main content LinkedIn Research Engineer, AI in Guwahati Expand search This button displays the currently selected search type. When expanded it provides a list of search options that will switch the search inputs to match the current selection. Jobs People Learning Clear text Clear text Clear text Clear text Clear text Join now Sign in Research Engineer, AI SHL Gurgaon, Haryana, India Research Engineer, AI SHL Gurgaon, Haryana, India 2 weeks ago Be among the first 25 applicants See who SHL has hired for this role Report this job Use AI to assess how you fit Get AI-powered advice on this job and more exclusive features. Am I a good fit for this job? Tailor my resume Sign in to access AI-powered advices Sign in Welcome back Email or phone Password Show Forgot password? Sign in or By clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement , Privacy Policy , and Cookie Policy . New to LinkedIn? Join now or New to LinkedIn? Join now By clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement , Privacy Policy , and Cookie Policy . Sign in to evaluate your skills Sign in Welcome back Email or phone Password Show Forgot password? Sign in or By clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement , Privacy Policy , and Cookie Policy . New to LinkedIn? Join now or New to LinkedIn? Join now By clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement , Privacy Policy , and Cookie Policy . Sign in to tailor your resume Sign in Welcome back Email or phone Password Show Forgot password? Sign in or By clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement , Privacy Policy , and Cookie Policy . New to LinkedIn? Join now or New to LinkedIn? Join now By clicking Continue to join or sign in, you agree to LinkedIn’s User Agreement , Privacy Policy , and Cookie Policy . Job Description Join a community that is shaping the future of work! SHL, People Science. People Answers. Are you an AI enthusiastwith visionary thinking to conceptualize AI-based products? Are you looking to apply these skills in an environment where teamwork and collaboration are key to developing our digital product experiences? We are seeking a Research Engineer to join our team to deliver robust AI/ML models. You will closely work with the product team to spot opportunities to use AI in the current product stack and influence the product roadmap by incorporating AI-led features/products. An excellent benefits package is offered in a culture where career development, with ongoing manager guidance, collaboration, flexibility, diversity, and inclusivity are all intrinsic to our culture.  There is a huge investment in SHL currently so there’s no better time to become a part of something transformational. What You Will Be Doing Develop and experiment with machine learning models like NLP, computer vision etc. Prototype and fine-tune generative AI models for text, image, speech, and video generation. Implement emerging LLM technologies and monitoring tools. Manage the entire AI/ML lifecycle from research to deployment and maintenance. Optimize models for scalability, efficiency, and performance. Collaborate with ML engineers for solution delivery and propose AI-driven enhancements. Contribute to research, documentation, and publications with AI/ML advancements. Essential What we are looking for from you: Relevant experience in AI/ML - NLP, speech processing, and computer vision. Proficiency in Python and ML frameworks such as TensorFlow, PyTorch, & OpenAI APIs. Good knowledge of ML theory deep learning, and statistical modeling. Desirable Familiarity with Generative AI (LLMs & RAG). Experience in prototyping and deploying AI. Agile and proactive thinking. Get In Touch Find out how this one-off opportunity can help you to achieve your career goals by making an application to our knowledgeable and friendly Talent Acquisition team. Choose a new path with SHL. #CareersAtSHL #SHLHiringTalent #AIJobs #ResearchJobs #MLJobs #CareerOpportunities #JobOpportunities About Us We unlock the possibilities of businesses through the power of people, science and technology. We started this industry of people insight more than 40 years ago and continue to lead the market with powerhouse product launches, ground-breaking science and business transformation. When you inspire and transform people’s lives, you will experience the greatest business outcomes possible. SHL’s products insights, experiences, and services can help achieve growth at scale. What SHL Can Offer You Diversity, equity, inclusion and accessibility are key threads in the fabric of SHL’s business and culture (find out more about DEI and accessibility at SHL ) Employee benefits package that takes care of you and your family. Support, coaching, and on-the-job development to achieve career success A fun and flexible workplace where you’ll\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "import logging\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set up logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def extract_text_from_url(url: str) -> str:\n",
    "    \"\"\"Extract text content from a URL using BeautifulSoup\"\"\"\n",
    "    try:\n",
    "        # Validate URL\n",
    "        parsed_url = urlparse(url)\n",
    "        if not parsed_url.scheme or not parsed_url.netloc:\n",
    "            print(\"Invalid URL. Please enter a valid URL.\")\n",
    "            return \"\"\n",
    "        \n",
    "        # Fetch content\n",
    "        with httpx.Client(timeout=10.0) as client:\n",
    "            response = client.get(url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse HTML with BeautifulSoup\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "            \n",
    "            # Limit length for preview\n",
    "            return text[:5000]\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting text from URL: {str(e)}\")\n",
    "        print(f\"Error extracting text from URL: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "# Test the function with the provided URL\n",
    "url = \"https://www.linkedin.com/jobs/view/research-engineer-ai-at-shl-4194768899/?originalSubdomain=in\"\n",
    "extracted_text = extract_text_from_url(url)\n",
    "print(extracted_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
